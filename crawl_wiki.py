import wikipediaapi
import os
import re
from tqdm import tqdm


# --- Cáº¤U HÃŒNH ---
OUTPUT_FILE = "data/documents.txt"
LANG = "vi"


# Danh sÃ¡ch tá»« khÃ³a
TOPICS = [
    # --- 1. NHÃ‚N Váº¬T Lá»ŠCH Sá»¬ & CHÃNH TRá»Š ---
    "Há»“ ChÃ­ Minh", "VÃµ NguyÃªn GiÃ¡p", "Tráº§n HÆ°ng Äáº¡o", "Quang Trung", "Nguyá»…n Huá»‡",
    "Tráº§n NhÃ¢n TÃ´ng", "Tráº§n ThÃ¡nh TÃ´ng", "KhÃ¢m Tá»« HoÃ ng", "Máº¡c ÄÄƒng Dung", "Máº¡c ÄÄ©nh Chi",
    "LÃª ChiÃªu Thá»‘ng", "Nguyá»…n Há»¯u Chá»‰nh", "Trá»‹nh Bá»“ng", "Nguyá»…n ThÃ¡i Há»c",
    "TÆ°á»Ÿng Giá»›i Tháº¡ch", "Há»‘t Táº¥t Liá»‡t", "ThÃ nh CÃ¡t TÆ° HÃ£n", "Táº§n Thá»§y HoÃ ng", "CÃ n Long",
    "FranÃ§ois Mitterrand", "Saddam Hussein", "Gioan PhaolÃ´ II", "Friedrich Wilhelm",
    "Augustine xá»© Hippo", "Jacques Lacan",


    # --- 2. Sá»° KIá»†N & Tá»” CHá»¨C ---
    "Viá»‡t Nam Quá»‘c dÃ¢n Äáº£ng", "Khá»Ÿi nghÄ©a YÃªn BÃ¡i", "NhÃ  tÃ¹ Há»a LÃ²",
    "Chiáº¿n dá»‹ch Äiá»‡n BiÃªn Phá»§", "Chiáº¿n tranh tháº¿ giá»›i thá»© hai", "Khá»‘i Warszawa",
    "Äáº£ng Cá»™ng sáº£n Viá»‡t Nam", "Äáº£ng Lao Ä‘á»™ng Viá»‡t Nam", "Trung Æ°Æ¡ng Cá»¥c miá»n Nam",
    "Äáº¡i Viá»‡t", "Äáº¡i NguyÃªn", "Háº­u LÃª", "TÃ¢y SÆ¡n",


    # --- 3. Äá»ŠA DANH & QUá»C GIA ---
    "Viá»‡t Nam", "Trung Quá»‘c", "Hoa Ká»³", "LiÃªn XÃ´", "áº¤n Äá»™", "Nháº­t Báº£n", "HÃ n Quá»‘c",
    "HÃ  Ná»™i", "SÃ i GÃ²n", "ÄÃ  Náºµng", "Háº£i PhÃ²ng", "Quáº£ng Ninh", "Thanh HÃ³a", "Nghá»‡ An",
    "YÃªn BÃ¡i", "Láº¡ng SÆ¡n", "ThÆ°á»ng XuÃ¢n", "HÃ²a Phong", "Äáº£o Jaffna", "Palm Jumeirah",
    "Ba Lan", "Estonia", "Hy Láº¡p", "Thá»• NhÄ© Ká»³", "Ai Cáº­p", "Nam TÆ°", "TÃ¢y Táº¡ng",
    "Há»“ng KÃ´ng", "ÄÃ i Loan", "Ann Arbor", "New York",


    # --- 4. VÄ‚N HÃ“A, NGHá»† THUáº¬T & GIáº¢I TRÃ ---
    "LÃª Minh SÆ¡n", "Thanh Lam", "HÃ  Tráº§n", "Tráº§n Tiáº¿n", "Nguyá»…n VÄƒn BÃ¬nh",
    "Cá»• ThiÃªn Láº¡c", "TrÆ°Æ¡ng Quá»‘c Vinh", "VÆ°Æ¡ng Gia Vá»‡", "Diá»‡p Váº¥n", "Cung Nhá»‹", "MÃ£ Tam",
    "Major Lazer", "DJ Snake", "Lean On", "Assume Form",
    "Pháº­t giÃ¡o Viá»‡t Nam", "ChÃ¹a Quang Hoa", "ChÃ¹a Thiá»n Quang", "ChÃ¹a BÃ¡o Ã‚n", "ChÃ¹a Ba La Máº­t",


    # --- 5. SINH Há»ŒC & Y Há»ŒC ---
    "Khá»‰ thÃ­ nghiá»‡m", "Khá»‰ vÃ ng", "Khá»‰ Ä‘uÃ´i dÃ i", "Váº¯c-xin báº¡i liá»‡t",
    "Tráº§m cáº£m", "Setter Anh Quá»‘c", "TÃ¡o Granny Smith", "SÃ¢m Ngá»c Linh",
    "VÅ© khÃ­ sinh há»c", "VÅ© khÃ­ hÃ³a há»c", "VÅ© khÃ­ há»§y diá»‡t hÃ ng loáº¡t",


    # --- 6. KINH Táº¾ & TOÃN LÃ ---
    "Tá»•ng sáº£n pháº©m ná»™i Ä‘á»‹a", "Láº¡m phÃ¡t", "LÃ£i suáº¥t thá»±c", "Kháº¥u hao",
    "Khuynh hÆ°á»›ng tiÃªu dÃ¹ng biÃªn", "Äá»™ co giÃ£n cá»§a cáº§u",
    "SÃ³ng cÆ¡", "SÃ³ng dá»c", "SÃ³ng ngang", "Äiá»‡n trá»Ÿ", "Äá»‹nh luáº­t Ohm",
    "LÆ°á»£ng giÃ¡c", "Há»‡ hai má»©c nÄƒng lÆ°á»£ng", "Thuyáº¿t tÆ°Æ¡ng Ä‘á»‘i háº¹p"
]


def clean_wiki_content(content):
    """LÃ m sáº¡ch ná»™i dung Wikipedia."""
    content = re.sub(r'==\s*(Xem thÃªm|Tham kháº£o|ChÃº thÃ­ch|LiÃªn káº¿t ngoÃ i|Äá»c thÃªm)\s*==.*', '', content, flags=re.DOTALL | re.IGNORECASE)
    content = re.sub(r'={2,}', '', content)
    content = re.sub(r'\n{3,}', '\n\n', content)
    return content.strip()


def get_existing_titles(file_path):
    """Äá»c file hiá»‡n táº¡i Ä‘á»ƒ láº¥y danh sÃ¡ch cÃ¡c tiÃªu Ä‘á» Ä‘Ã£ cÃ³."""
    existing_titles = set()
    if not os.path.exists(file_path):
        return existing_titles
   
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                # Kiá»ƒm tra dÃ²ng báº¯t Ä‘áº§u báº±ng format tiÃªu Ä‘á» mÃ¬nh quy Ä‘á»‹nh
                if line.startswith("Chá»§ Ä‘á»: "):
                    # Láº¥y pháº§n tÃªn sau dáº¥u hai cháº¥m vÃ  xÃ³a khoáº£ng tráº¯ng thá»«a
                    title = line.replace("Chá»§ Ä‘á»: ", "").strip()
                    existing_titles.add(title)
    except Exception as e:
        print(f"âš ï¸ Cáº£nh bÃ¡o: KhÃ´ng thá»ƒ Ä‘á»c file cÅ© ({e}). Sáº½ táº¡o file má»›i hoáº·c ghi Ä‘Ã¨.")
   
    return existing_titles


def crawl_wiki():
    wiki = wikipediaapi.Wikipedia(
        user_agent='VNPT_Hackathon_Bot/1.0 (test@example.com)',
        language=LANG,
        extract_format=wikipediaapi.ExtractFormat.WIKI
    )


    # 1. Láº¥y danh sÃ¡ch bÃ i Ä‘Ã£ cÃ³ Ä‘á»ƒ trÃ¡nh trÃ¹ng láº·p
    existing_titles = get_existing_titles(OUTPUT_FILE)
    print(f"ğŸ“‚ ÄÃ£ tÃ¬m tháº¥y {len(existing_titles)} bÃ i viáº¿t cÃ³ sáºµn trong dá»¯ liá»‡u.")


    print(f"ğŸ•·ï¸ Äang báº¯t Ä‘áº§u xá»­ lÃ½ {len(TOPICS)} chá»§ Ä‘á»...")
   
    new_articles_count = 0


    with open(OUTPUT_FILE, 'a', encoding='utf-8') as f:
        # Náº¿u file chÆ°a cÃ³ dá»¯ liá»‡u hoáº·c má»›i táº¡o, thÃªm header
        if os.path.getsize(OUTPUT_FILE) == 0:
            f.write("\n" + "="*50 + "\nDATA FROM WIKIPEDIA CRAWLER\n" + "="*50 + "\n\n")


        for topic in tqdm(TOPICS):
            page = wiki.page(topic)


            if page.exists():
                title = page.title.strip()


                # --- KIá»‚M TRA TRÃ™NG Láº¶P ---
                if title in existing_titles:
                    # Bá» qua náº¿u Ä‘Ã£ cÃ³
                    continue


                # LÃ€M Sáº CH Ná»˜I DUNG
                content = clean_wiki_content(page.text)
               
                if len(content) < 100: continue


                # Ghi vÃ o file
                entry = f"Chá»§ Ä‘á»: {title}\n"
                entry += f"{content}\n"
                entry += "\n" + "-"*30 + "\n\n"
               
                f.write(entry)
               
                # Cáº­p nháº­t danh sÃ¡ch Ä‘Ã£ cÃ³ (Ä‘á»ƒ trÃ¡nh trÃ¹ng láº·p ngay trong chÃ­nh danh sÃ¡ch TOPICS Ä‘áº§u vÃ o)
                existing_titles.add(title)
                new_articles_count += 1
            else:
                # Chá»‰ in lá»—i náº¿u bÃ i thá»±c sá»± khÃ´ng tá»“n táº¡i trÃªn Wiki
                # print(f"âš ï¸ KhÃ´ng tÃ¬m tháº¥y trÃªn Wiki: {topic}")
                pass


    print(f"âœ… HoÃ n táº¥t! ÄÃ£ thÃªm má»›i {new_articles_count} bÃ i viáº¿t vÃ o {OUTPUT_FILE}.")


if __name__ == "__main__":
    if not os.path.exists("data"):
        os.makedirs("data")
       
    crawl_wiki()

