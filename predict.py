import json
import re
import time
import requests
import chromadb
from tqdm import tqdm
import config # File config c·ªßa b·∫°n
import sys
import pandas as pd

try:
    __import__('pysqlite3')
    sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')
except ImportError:
    pass

# --- C·∫§U H√åNH ---
BLACKLIST_KEYWORDS = ["sex", "khi√™u d√¢m", "ma t√∫y", "c·ªù b·∫°c", "l·ª´a ƒë·∫£o", "kh·ªßng b·ªë", "t·ª± t·ª≠", "hacking", "ph√¢n bi·ªát ch·ªßng t·ªôc", "x√∫c ph·∫°m", "lƒÉng m·∫°"] 
SAFE_ANSWER_DEFAULT = "A" # M·∫∑c ƒë·ªãnh tr·∫£ v·ªÅ A (ch·ªØ c√°i)
PARSE_FAIL_FLAG = "X"

# =========================================================
# K·∫æT N·ªêI VECTOR DB
# =========================================================

try:
    client = chromadb.PersistentClient(path="./vector_db")
    collection = client.get_or_create_collection(name="vnpt_knowledge")
except Exception:
    collection = None


# =========================================================
# EMBEDDING
# =========================================================

def get_embedding_for_search(text):
    payload = {
        "model": "vnptai_hackathon_embedding",
        "input": text,
        "encoding_format": "float",
    }

    for _ in range(3):
        try:
            resp = requests.post(
                config.URL_EMBEDDING,
                headers=config.HEADERS_EMBED,
                json=payload,
                timeout=5,
            )
            if resp.status_code == 200:
                return resp.json()["data"][0]["embedding"]
        except Exception:
            time.sleep(0.5)

    return None


# =========================================================
# PH√ÇN LO·∫†I C√ÇU H·ªéI & AN TO√ÄN
# =========================================================

def detect_question_type_and_safety(question):
    q_lower = question.lower()

    for bad_word in BLACKLIST_KEYWORDS:
        if bad_word in q_lower:
            return "UNSAFE"

    stem_keywords = [
        "t√≠nh", "gi√° tr·ªã", "ph∆∞∆°ng tr√¨nh", "h√†m s·ªë", "bi·ªÉu th·ª©c",
        "x√°c su·∫•t", "th·ªëng k√™", "log", "sin", "cos", "tan", "cot",
        "ƒë·∫°o h√†m", "t√≠ch ph√¢n", "nguy√™n h√†m", "vector", "ma tr·∫≠n",
        "v·∫≠n t·ªëc", "gia t·ªëc", "l·ª±c", "ƒëi·ªán tr·ªü", "nƒÉng l∆∞·ª£ng", "c√¥ng su·∫•t",
        "l√£i su·∫•t", "gdp", "l·∫°m ph√°t", "cung c·∫ßu", "ƒë·ªô co gi√£n",
        "mol", "ph·∫£n ·ª©ng", "c√¢n b·∫±ng", "kh·ªëi l∆∞·ª£ng", "latex", "$", "\\frac" 
        ]

    if any(k in q_lower for k in stem_keywords):
        return "STEM"

    precision_keywords = [
        "nƒÉm n√†o", "ng√†y n√†o", "ai l√†", "ng∆∞·ªùi n√†o", "·ªü ƒë√¢u",
        "bao nhi√™u", "s·ªë l∆∞·ª£ng", "th·ªùi gian n√†o",
        "ngh·ªã ƒë·ªãnh", "lu·∫≠t", "th√¥ng t∆∞", "ƒëi·ªÅu kho·∫£n", "hi·∫øn ph√°p",
        "th·ªß ƒë√¥", "di t√≠ch", "chi·∫øn d·ªãch", "hi·ªáp ƒë·ªãnh",
    ]

    if any(k in q_lower for k in precision_keywords):
        return "PRECISION"

    return "NORMAL"


def clean_output(ans_text):
    # 1. X·ª≠ l√Ω tr∆∞·ªùng h·ª£p ans_text l√† None (L·ªói Server/Key/429/Timeout)
    if ans_text is None:
        # Tr·∫£ v·ªÅ None: D√πng ƒë·ªÉ k√≠ch ho·∫°t Fallback trong solve_question
        return None 

    # 2. X·ª≠ l√Ω tr∆∞·ªùng h·ª£p ans_text l√† chu·ªói r·ªóng "" (L·ªói 400 Content Filter)
    if ans_text == "":
        # Tr·∫£ v·ªÅ "Z": D√πng ƒë·ªÉ b√°o hi·ªáu C·∫§M TR·∫¢ L·ªúI trong solve_question
        return "Z"
    
    # K·ªÉ t·ª´ ƒë√¢y, ans_text l√† m·ªôt chu·ªói kh√¥ng r·ªóng
    if not isinstance(ans_text, str):
        # Tr∆∞·ªùng h·ª£p input kh√¥ng ph·∫£i chu·ªói, coi l√† l·ªói Parsing/format
        return PARSE_FAIL_FLAG # Tr·∫£ v·ªÅ "X"

    ans_text = ans_text.strip()

    # ... (c√°c b∆∞·ªõc parsing b·∫±ng regex) ...

    tag_match = re.search(
        r"<ans>\s*([A-Ja-j])\s*</ans>",
        ans_text,
        re.IGNORECASE
    )
    if tag_match:
        return tag_match.group(1).upper()

    mid_match = re.search(
        r"(ƒë√°p √°n|answer|ans)\s*[:\-]?\s*\(?([A-Ja-j])\)?",
        ans_text,
        re.IGNORECASE
    )
    if mid_match:
        return mid_match.group(2).upper()

    last_match = re.search(
        r"\b([A-Ja-j])\s*[\.\)\]]*\s*$",
        ans_text,
        re.IGNORECASE
    )
    if last_match:
        return last_match.group(1).upper()

    # 3. Fallback cu·ªëi c√πng n·∫øu parsing th·∫•t b·∫°i (ƒê√É S·ª¨A)
    # Tr·∫£ v·ªÅ c·ªù "X" ƒë·ªÉ Fallback logic trong solve_question bi·∫øt ƒë√¢y l√† l·ªói Parse
    return PARSE_FAIL_FLAG


# =========================================================
# G·ªåI LLM
# =========================================================

def call_vnpt_llm(prompt, model_type="small", temperature=0.0):

    if model_type == "large":
        url = config.URL_LLM_LARGE
        headers = config.HEADERS_LARGE
        model_name = "vnptai_hackathon_large"
    else:
        url = config.URL_LLM_SMALL
        headers = config.HEADERS_SMALL
        model_name = "vnptai_hackathon_small"

    payload = {
        "model": model_name,
        "messages": [{"role": "user", "content": prompt}],
        "temperature": temperature,
        "max_completion_tokens": 20,
        "stop": ["</ans>", "\n"]
    }

    for attempt in range(3):
        try:
            r = requests.post(
                url,
                headers=headers,
                json=payload,
                timeout=60
            )

            if r.status_code == 200:
                data = r.json() # ‚úÖ Th√™m d√≤ng n√†y
                # ... (x·ª≠ l√Ω 200) ...
                return data["choices"][0]["message"]["content"]


            if r.status_code == 401:
                print(f"‚ùå {model_type.upper()} 401 ‚Äì H·∫øt quota / quy·ªÅn")
                return None

            # S·ª¨A L·ªñI 429: S·ª≠ d·ª•ng th·ªùi gian ch·ªù tƒÉng d·∫ßn
            if r.status_code == 429:
                wait_time = 60 + (attempt * 60) 
                print(f"‚è≥ {model_type.upper()} rate limit ‚Üí ng·ªß {wait_time}s")
                time.sleep(wait_time)
                continue
                
            if r.status_code == 400:
                 # Logic n√†y ƒë√£ ƒë√∫ng: D·ª´ng retry v√¨ prompt kh√¥ng thay ƒë·ªïi
                 print(f"‚ùå {model_type.upper()} 400 ‚Äì L·ªói Content Filter. D·ª´ng retry.")
                 return ""

            print(f"‚ö†Ô∏è {model_type.upper()} HTTP {r.status_code}: {r.text}")
            time.sleep(5)

        except requests.exceptions.ReadTimeout:
            print(f"‚è≥ {model_type.upper()} timeout ‚Üí retry")
            time.sleep(5)

    return None





# =========================================================
# GI·∫¢I C√ÇU H·ªéI
# =========================================================

def solve_question(item):
    question = item["question"]
    choices = item["choices"]

    q_type = detect_question_type_and_safety(question)

    if q_type == "UNSAFE":
        return SAFE_ANSWER_DEFAULT, "N/A (UNSAFE QUESTION/FILTERED)"

    context_text = ""
    real_question = question
    is_reading_comprehension = "ƒêo·∫°n th√¥ng tin:" in question

    if is_reading_comprehension:
        parts = question.split("C√¢u h·ªèi:")
        context_text = parts[0].strip()
        real_question = parts[1].strip() if len(parts) > 1 else question
    elif collection:
        query_vec = get_embedding_for_search(real_question)
        if query_vec:
            results = collection.query(
                query_embeddings=[query_vec],
                n_results=5,
            )
            if results["documents"]:
                docs = results["documents"][0]
                context_text = "\n---\n".join(docs)

    # --- GI·ªÆ NGUY√äN format choices (0. ..., 1. ...) cho ƒë·ª° m·∫•t c√¥ng ---
    choices_str = (
        "\n. ".join([f"{i}. {v}" for i, v in enumerate(choices)])
        if isinstance(choices, list)
        else str(choices)
    )

    # --- Prompt ch·ªâ th·ªã LLM tr·∫£ v·ªÅ ch·ªØ c√°i t∆∞∆°ng ·ª©ng ---
    instruction_text = "H√£y ch·ªçn ƒë√°p √°n ƒë√∫ng (t∆∞∆°ng ·ª©ng 0->A, 1->B, 2->C, 3->D, 4->E, 5->F, 6->G, 7->H, 8->I, 9->J) v√† ch·ªâ tr·∫£ v·ªÅ ch·ªØ c√°i (A, B, C, D, E, F, G, H, I, J). B·∫ÆT BU·ªòC: ƒê√°p √°n cu·ªëi c√πng ph·∫£i n·∫±m trong th·∫ª <ans>, v√≠ d·ª•: <ans>A</ans>."

    if q_type == "STEM":
        prompt = f"""
        B·∫°n l√† Gi√°o s∆∞ Khoa h·ªçc T·ª± nhi√™n. Nhi·ªám v·ª•: Gi·∫£i b√†i t·∫≠p m·ªôt c√°ch CH√çNH X√ÅC TUY·ªÜT ƒê·ªêI.
        Kh√¥ng ƒë∆∞·ª£c ƒëo√°n. Kh√¥ng ƒë∆∞·ª£c suy di·ªÖn ngo√†i d·ªØ ki·ªán.



        --- C√îNG TH·ª®C & KI·∫æN TH·ª®C B·ªî TR·ª¢ (CONTEXT) ---

        CH·ªà ƒë∆∞·ª£c s·ª≠ d·ª•ng c√¥ng th·ª©c v√† ki·∫øn th·ª©c xu·∫•t hi·ªán trong CONTEXT d∆∞·ªõi ƒë√¢y.
        N·∫øu kh√¥ng c√≥ c√¥ng th·ª©c ph√π h·ª£p trong CONTEXT ‚Üí kh√¥ng ƒë∆∞·ª£c t·ª± suy ra c√¥ng th·ª©c kh√°c.

        {context_text}



        --- B√ÄI TO√ÅN ---

        C√¢u h·ªèi: {real_question}

        C√°c l·ª±a ch·ªçn (Index t·ª´ 0):
        {choices_str}



        --- QUY TR√åNH GI·∫¢I (B·∫ÆT BU·ªòC TU√ÇN THEO) ---

        1. X√°c ƒë·ªãnh DUY NH·∫§T c√¥ng th·ª©c/ƒë·ªãnh l√Ω c·∫ßn d√πng t·ª´ CONTEXT.
        2. Tr√≠ch xu·∫•t CH√çNH X√ÅC t·∫•t c·∫£ c√°c gi√° tr·ªã s·ªë v√† ƒë∆°n v·ªã trong ƒë·ªÅ b√†i.
        3. Th·ª±c hi·ªán t√≠nh to√°n n·ªôi b·ªô.
        4. ƒê·ªêI CHI·∫æU k·∫øt qu·∫£ t√≠nh ƒë∆∞·ª£c v·ªõi T·ª™NG l·ª±a ch·ªçn:
        - Lo·∫°i b·ªè c√°c ƒë√°p √°n sai ƒë∆°n v·ªã.
        - Lo·∫°i b·ªè c√°c ƒë√°p √°n kh√¥ng kh·ªõp gi√° tr·ªã.
        5. Ch·ªâ ch·ªçn ƒë√°p √°n kh·ªõp CH√çNH X√ÅC nh·∫•t v·ªõi k·∫øt qu·∫£ t√≠nh to√°n.
        6. N·∫øu kh√¥ng c√≥ ƒë√°p √°n n√†o kh·ªõp ch√≠nh x√°c ‚Üí ch·ªçn ƒë√°p √°n KH·ªöP NH·∫§T V·ªÄ GI√Å TR·ªä V√Ä ƒê∆†N V·ªä
            nh∆∞ng CH·ªà khi sai s·ªë nh·ªè v√† c√≥ th·ªÉ do l√†m tr√≤n s·ªë.
            N·∫øu kh√¥ng ‚Üí v·∫´n ch·ªçn ƒë√°p √°n kh·ªõp nh·∫•t v·ªÅ ƒê∆†N V·ªä.




        --- KI·ªÇM TRA L·∫†I (SELF-CHECK) ---

        Tr∆∞·ªõc khi tr·∫£ l·ªùi:
        - T·ª± ki·ªÉm tra l·∫°i ph√©p t√≠nh m·ªôt l·∫ßn.
        - ƒê·∫£m b·∫£o index ƒë∆∞·ª£c ch·ªçn ƒë√∫ng v·ªõi n·ªôi dung ƒë√°p √°n.



        --- Y√äU C·∫¶U ƒê·∫¶U RA (B·∫ÆT BU·ªòC) ---

        - KH√îNG tr√¨nh b√†y l·ªùi gi·∫£i.
        - KH√îNG gi·∫£i th√≠ch.
        - ƒê√°p √°n tr·∫£ v·ªÅ d·ª±a tr√™n h∆∞·ªõng d·∫´n sau: {instruction_text}
        """

    else:

        prompt = f"""
        B·∫°n l√† chuy√™n gia ph√¢n t√≠ch th√¥ng tin. Nhi·ªám v·ª•: tr·∫£ l·ªùi c√¢u h·ªèi
        CH·ªà d·ª±a tr√™n vƒÉn b·∫£n ƒë∆∞·ª£c cung c·∫•p. Kh√¥ng d√πng ki·∫øn th·ª©c b√™n ngo√†i.



        --- VƒÇN B·∫¢N THAM KH·∫¢O (CONTEXT) ---

        {context_text}



        --- C√ÇU H·ªéI ---

        {real_question}



        --- C√ÅC L·ª∞A CH·ªåN ---

        {choices_str}



        --- B∆Ø·ªöC 1: PH√ÇN LO·∫†I C√ÇU H·ªéI (TH·ª∞C HI·ªÜN N·ªòI B·ªò) ---

        X√°c ƒë·ªãnh c√¢u h·ªèi thu·ªôc lo·∫°i n√†o:
        A. Truy xu·∫•t th√¥ng tin tr·ª±c ti·∫øp
        (ai, khi n√†o, ·ªü ƒë√¢u, s·ª± ki·ªán g√¨, nh√¢n v·∫≠t n√†o...)
        B. Nh·∫≠n ƒë·ªãnh / ƒë√°nh gi√° / theo ng·ªØ c·∫£nh
        (vai tr√≤, √Ω nghƒ©a, nh·∫≠n x√©t, ƒë√°nh gi√°, nguy√™n nh√¢n...)



        --- B∆Ø·ªöC 2: CHI·∫æN L∆Ø·ª¢C THEO LO·∫†I ---

        [TR∆Ø·ªúNG H·ª¢P A ‚Äì TRUY XU·∫§T TH√îNG TIN]

        - Ch·ªâ ch·ªçn th√¥ng tin ƒë∆∞·ª£c n√™u TR·ª∞C TI·∫æP trong CONTEXT.
        - N·∫øu CONTEXT c√≥ c√¢u tr·∫£ l·ªùi tr√πng kh·ªõp r√µ r√†ng v·ªõi c√¢u h·ªèi ‚Üí PH·∫¢I ch·ªçn ƒë√°p √°n ƒë√≥.
        - KH√îNG:
        + suy lu·∫≠n
        + ch·ªçn ng∆∞·ªùi/s·ª± ki·ªán c√πng nh√≥m
        + ch·ªçn th√¥ng tin li√™n quan gi√°n ti·∫øp

        V√≠ d·ª• c·∫•m:
        - C√¢u h·ªèi h·ªèi 1 nh√¢n v·∫≠t ‚Üí kh√¥ng ch·ªçn nh√¢n v·∫≠t kh√°c trong c√πng danh s√°ch.



        [TR∆Ø·ªúNG H·ª¢P B ‚Äì NH·∫¨N ƒê·ªäNH / THEO NG·ªÆ C·∫¢NH]

        - ƒê·ªçc TO√ÄN B·ªò ƒëo·∫°n li√™n quan.
        - X√°c ƒë·ªãnh c√°c LU·ªíNG QUAN ƒêI·ªÇM n·∫øu c√≥ (·ªßng h·ªô / ph·∫£n ƒë·ªëi).
        - ∆Øu ti√™n ƒë√°p √°n ph·∫£n √°nh ƒê·∫¶Y ƒê·ª¶ ng·ªØ c·∫£nh.
        - Kh√¥ng ch·ªçn ƒë√°p √°n:
        + ch·ªâ ƒë√∫ng m·ªôt ph√≠a
        + ho·∫∑c kh√¥ng ƒë∆∞·ª£c CONTEXT h·ªó tr·ª£ r√µ r√†ng.



        --- B∆Ø·ªöC 3: KI·ªÇM TRA CU·ªêI (B·∫ÆT BU·ªòC) ---

        Tr∆∞·ªõc khi tr·∫£ l·ªùi, t·ª± ki·ªÉm tra:
        - ƒê√°p √°n c√≥ ƒë∆∞·ª£c n√™u tr·ª±c ti·∫øp ho·∫∑c suy ra r√µ r√†ng t·ª´ CONTEXT kh√¥ng?
        - C√≥ ƒë√°p √°n n√†o kh·ªõp TR·ª∞C TI·∫æP h∆°n kh√¥ng?
        - C√≥ ch·ªçn nh·∫ßm ng∆∞·ªùi/s·ª± ki·ªán c√πng nh√≥m kh√¥ng?



        --- Y√äU C·∫¶U ƒê·∫¶U RA (B·∫ÆT BU·ªòC) ---

        - KH√îNG gi·∫£i th√≠ch.
        - ƒê√°p √°n tr·∫£ v·ªÅ d·ª±a tr√™n h∆∞·ªõng d·∫´n sau: {instruction_text}
        """

    # ================================
    # 1Ô∏è‚É£ LU√îN G·ªåI SMALL TR∆Ø·ªöC
    # ================================
    ans_small = call_vnpt_llm(prompt, model_type="small", temperature=0.0)
    final_choice = clean_output(ans_small) # final_choice l√† A-J, None, Z, ho·∫∑c X

    # --- KI·ªÇM TRA L·ªñI 400 NGAY L·∫¨P T·ª®C (D·∫•u hi·ªáu: Z) ---
    if final_choice == "Z":
        print("üõë Small LLM b·ªã Content Filter. Tr·∫£ v·ªÅ r·ªóng theo y√™u c·∫ßu.")
        return "", context_text # Tr·∫£ v·ªÅ chu·ªói r·ªóng ""

    # ================================
    # 2Ô∏è‚É£ FALLBACK LARGE (S·ª¨A L·ªñI LOGIC)
    # ================================
    # K√≠ch ho·∫°t Fallback n·∫øu: 
    # A. L·ªói Server/Key/Timeout (final_choice == None)
    # HO·∫∂C
    # B. L·ªói Parsing/V√¥ nghƒ©a (final_choice == PARSE_FAIL_FLAG "X")
    
    if final_choice is None or final_choice == PARSE_FAIL_FLAG: 
        
        print(f"üîÑ Fallback SMALL ‚Üí LARGE (Nguy√™n nh√¢n: {'L·ªói Server/Key' if final_choice is None else 'L·ªói Format'})")
        
        ans_large = call_vnpt_llm(prompt, model_type="large", temperature=0.0)
        large_choice = clean_output(ans_large)

        # --- KI·ªÇM TRA L·ªñI 400 C·ª¶A LARGE ---
        if large_choice == "Z":
            print("üõë Large LLM b·ªã Content Filter. Tr·∫£ v·ªÅ r·ªóng theo y√™u c·∫ßu.")
            return "", context_text 

        # --- G√ÅN K·∫æT QU·∫¢ LARGE HO·∫∂C G√ÅN M·∫∂C ƒê·ªäNH ---
        # N·∫øu Large tr·∫£ l·ªùi th√†nh c√¥ng (kh√¥ng ph·∫£i None, kh√¥ng ph·∫£i X), d√πng k·∫øt qu·∫£ Large
        if large_choice is not None and large_choice != PARSE_FAIL_FLAG:
             final_choice = large_choice # C·∫≠p nh·∫≠t k·∫øt qu·∫£ (A-J)
        else:
             # N·∫øu Large c≈©ng th·∫•t b·∫°i, tr·∫£ v·ªÅ ƒë√°p √°n m·∫∑c ƒë·ªãnh an to√†n
             final_choice = SAFE_ANSWER_DEFAULT
    
    # --- B∆Ø·ªöC CU·ªêI C√ôNG: ƒê·∫¢M B·∫¢O LU√îN C√ì K·∫æT QU·∫¢ H·ª¢P L·ªÜ ---
    # N·∫øu Small th√†nh c√¥ng, n√≥ s·∫Ω nh·∫£y qua Fallback v√† final_choice ƒë√£ l√† A-J.
    # N·∫øu Fallback x·∫£y ra, final_choice ƒë√£ ƒë∆∞·ª£c g√°n A-J ho·∫∑c SAFE_ANSWER_DEFAULT.
    
    # Tr∆∞·ªùng h·ª£p duy nh·∫•t c·∫ßn ki·ªÉm tra l·∫°i l√† n·∫øu c√≥ l·ªói logic kh√¥ng l∆∞·ªùng tr∆∞·ªõc.
    if final_choice is None or final_choice == PARSE_FAIL_FLAG:
        final_choice = SAFE_ANSWER_DEFAULT
        
    return final_choice, context_text


# print("TEST SMALL:")
# print(call_vnpt_llm("Ch·ªâ tr·∫£ l·ªùi <ans>A</ans>", "small"))

# print("TEST LARGE:")
# print(call_vnpt_llm("Ch·ªâ tr·∫£ l·ªùi <ans>A</ans>", "large"))


if __name__ == "__main__":
    # --- 1. C·∫§U H√åNH ---
    MODE = "LOCAL"
    INPUT_FILE_PATH = "data/val.json" 
    OUTPUT_FILE_PATH = "submission_local.csv"
    MAX_QUESTIONS_TO_PROCESS = None 
    
    if len(sys.argv) > 1:
        if sys.argv[1] == 'docker':
            MODE = "DOCKER"
            INPUT_FILE_PATH = "/code/private_test.json" 
            OUTPUT_FILE_PATH = "submission.csv"
        
        if len(sys.argv) > 2 and sys.argv[2].isdigit():
             MAX_QUESTIONS_TO_PROCESS = int(sys.argv[2])
        elif len(sys.argv) > 1 and sys.argv[1].isdigit():
            MAX_QUESTIONS_TO_PROCESS = int(sys.argv[1])
    
    print(f"üöÄ Ch·∫ø ƒë·ªô: {MODE} | Input: {INPUT_FILE_PATH}")
    
    try:
        # --- 2. ƒê·ªåC D·ªÆ LI·ªÜU ---
        try:
            with open(INPUT_FILE_PATH, "r", encoding="utf-8") as f:
                data = json.load(f) 
        except (json.JSONDecodeError, FileNotFoundError):
             df = pd.read_csv(INPUT_FILE_PATH)
             data = df.to_dict('records')
            
        total_data_length = len(data)
        data_to_process = data[:MAX_QUESTIONS_TO_PROCESS] if MAX_QUESTIONS_TO_PROCESS else data
        IS_FULL_RUN = len(data_to_process) == total_data_length
        IS_VAL_MODE = (MODE == "LOCAL" and "val.json" in INPUT_FILE_PATH)

        if MODE == "LOCAL" and not IS_FULL_RUN:
            print(f"‚ö†Ô∏è Debug: ƒêang ch·∫°y {len(data_to_process)}/{total_data_length} c√¢u.")
        
        # --- 3. X·ª¨ L√ù ---
        submission_results = []
        correct_count = 0
        wrong_cases = []
        
        print("üîÑ ƒêang x·ª≠ l√Ω c√¢u h·ªèi...")
        for item in tqdm(data_to_process):
            item_id = item.get("id", item.get("qid")) 

            # B1: G·ªçi h√†m x·ª≠ l√Ω (LLM tr·∫£ v·ªÅ A, B, C, D)
            pred_char, retrieved_context = solve_question(item)
            
            # B2: L∆∞u k·∫øt qu·∫£
            submission_results.append({
                "qid": item_id,
                "answer": pred_char
            })
            
            # B3: T√≠nh ƒëi·ªÉm (So s√°nh tr·ª±c ti·∫øp, kh√¥ng map g√¨ c·∫£)
            if IS_VAL_MODE:
                # ƒê√°p √°n th·∫≠t trong file JSON ƒë√£ l√† ch·ªØ c√°i (A, B, C...)
                true_char = str(item.get('answer', '?')).strip().upper()
                
                if pred_char == true_char:
                    correct_count += 1
                else:
                    wrong_cases.append({
                        "qid": item_id,
                        "question": item['question'],
                        "true_char": true_char,
                        "pred_char": pred_char,
                        "retrieved_context": retrieved_context 
                    })

        # --- 4. GHI FILE ---
        df = pd.DataFrame(submission_results)

        if MODE == "DOCKER" or (MODE == "LOCAL" and IS_FULL_RUN):
            df.to_csv(OUTPUT_FILE_PATH, index=False, encoding='utf-8')
            print(f"\n‚úÖ ƒê√£ l∆∞u file k·∫øt qu·∫£: {OUTPUT_FILE_PATH}")
        else:
            print("\nüíæ Debug xong (Kh√¥ng ghi file CSV).")

        # --- 5. T·ªîNG K·∫æT ---
        print("\n" + "="*40)
        if IS_VAL_MODE:
            acc = (correct_count / len(data_to_process)) * 100
            print(f"üèÜ Accuracy (T·∫≠p Val): {acc:.2f}%")
            
            if wrong_cases:
                pd.DataFrame(wrong_cases).to_csv("wrong_answers.csv", index=False, encoding='utf-8')
                print(f"‚ö†Ô∏è ƒê√£ l∆∞u {len(wrong_cases)} c√¢u sai v√†o 'wrong_answers.csv'")
        elif MODE == "DOCKER":
            print("‚úÖ Docker Run Complete.")
        else:
            print("üèÅ Test Run Complete.")
        print("="*40)
            
    except Exception as e:
        print(f"‚ùå L·ªói Nghi√™m Tr·ªçng: {e}")